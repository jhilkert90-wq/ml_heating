"""
ML Heating Dashboard - Model Backup & Restore Component
Complete data preservation and model management system
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import json
import os
import sys
import pickle
import shutil
import zipfile
import hashlib
from pathlib import Path

# Add app directory to Python path
sys.path.append('/app')

def get_model_files():
    """Get list of all ML model and data files"""
    model_files = {
        'models': [],
        'logs': [],
        'config': [],
        'analytics': []
    }
    
    # Model files
    model_dir = Path('/data/models')
    if model_dir.exists():
        for file_path in model_dir.glob('*.pkl'):
            stat = file_path.stat()
            model_files['models'].append({
                'name': file_path.name,
                'path': str(file_path),
                'size': stat.st_size,
                'modified': datetime.fromtimestamp(stat.st_mtime),
                'type': 'model'
            })
    
    # Log files
    log_dir = Path('/data/logs')
    if log_dir.exists():
        for file_path in log_dir.glob('*.log'):
            stat = file_path.stat()
            model_files['logs'].append({
                'name': file_path.name,
                'path': str(file_path),
                'size': stat.st_size,
                'modified': datetime.fromtimestamp(stat.st_mtime),
                'type': 'log'
            })
    
    # Config files
    config_dir = Path('/data/config')
    if config_dir.exists():
        for file_path in config_dir.glob('*'):
            if file_path.is_file():
                stat = file_path.stat()
                model_files['config'].append({
                    'name': file_path.name,
                    'path': str(file_path),
                    'size': stat.st_size,
                    'modified': datetime.fromtimestamp(stat.st_mtime),
                    'type': 'config'
                })
    
    return model_files

def get_existing_backups():
    """Get list of existing backup files"""
    backup_dir = Path('/data/backups')
    backup_dir.mkdir(exist_ok=True)
    
    backups = []
    for backup_file in backup_dir.glob('ml_backup_*.zip'):
        stat = backup_file.stat()
        
        # Extract timestamp from filename
        try:
            timestamp_str = backup_file.stem.replace('ml_backup_', '')
            timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
        except ValueError:
            timestamp = datetime.fromtimestamp(stat.st_mtime)
        
        # Calculate MD5 hash for integrity checking
        md5_hash = hashlib.md5()
        with open(backup_file, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                md5_hash.update(chunk)
        
        backups.append({
            'name': backup_file.name,
            'path': str(backup_file),
            'size': stat.st_size,
            'created': timestamp,
            'modified': datetime.fromtimestamp(stat.st_mtime),
            'md5': md5_hash.hexdigest()
        })
    
    return sorted(backups, key=lambda x: x['created'], reverse=True)

def create_backup(backup_name=None, include_logs=True, include_analytics=True):
    """Create a comprehensive backup of ML system state"""
    try:
        if not backup_name:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_name = f'ml_backup_{timestamp}'
        
        backup_dir = Path('/data/backups')
        backup_dir.mkdir(exist_ok=True)
        
        backup_path = backup_dir / f'{backup_name}.zip'
        
        with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as backup_zip:
            # Backup models directory
            models_dir = Path('/data/models')
            if models_dir.exists():
                for file_path in models_dir.rglob('*'):
                    if file_path.is_file():
                        arcname = f'models/{file_path.relative_to(models_dir)}'
                        backup_zip.write(file_path, arcname)
            
            # Backup configuration
            config_dir = Path('/data/config')
            if config_dir.exists():
                for file_path in config_dir.rglob('*'):
                    if file_path.is_file():
                        arcname = f'config/{file_path.relative_to(config_dir)}'
                        backup_zip.write(file_path, arcname)
            
            # Backup add-on configuration
            addon_config = Path('/data/options.json')
            if addon_config.exists():
                backup_zip.write(addon_config, 'addon_config.json')
            
            # Include logs if requested
            if include_logs:
                logs_dir = Path('/data/logs')
                if logs_dir.exists():
                    for file_path in logs_dir.glob('*.log'):
                        arcname = f'logs/{file_path.name}'
                        backup_zip.write(file_path, arcname)
            
            # Create backup manifest
            manifest = {
                'created': datetime.now().isoformat(),
                'backup_name': backup_name,
                'include_logs': include_logs,
                'include_analytics': include_analytics,
                'files_backed_up': [],
                'system_info': {
                    'addon_version': '1.0',
                    'python_version': sys.version,
                    'platform': os.name
                }
            }
            
            # Add file list to manifest
            for file_info in backup_zip.filelist:
                manifest['files_backed_up'].append({
                    'filename': file_info.filename,
                    'file_size': file_info.file_size,
                    'compress_size': file_info.compress_size
                })
            
            # Write manifest
            manifest_json = json.dumps(manifest, indent=2)
            backup_zip.writestr('backup_manifest.json', manifest_json)
        
        return True, backup_path, manifest
        
    except Exception as e:
        return False, None, str(e)

def restore_backup(backup_path, restore_models=True, restore_config=True, restore_logs=False):
    """Restore ML system from backup"""
    try:
        backup_file = Path(backup_path)
        if not backup_file.exists():
            return False, "Backup file not found"
        
        # Create restoration timestamp
        restore_time = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Backup current state before restoration
        current_backup_name = f'pre_restore_{restore_time}'
        success, _, _ = create_backup(current_backup_name, include_logs=False)
        if not success:
            return False, "Failed to backup current state before restoration"
        
        with zipfile.ZipFile(backup_file, 'r') as backup_zip:
            # Read manifest
            manifest = {}
            try:
                manifest_data = backup_zip.read('backup_manifest.json')
                manifest = json.loads(manifest_data)
            except KeyError:
                st.warning("Backup manifest not found - proceeding with basic restore")
            
            # Restore models
            if restore_models:
                models_dir = Path('/data/models')
                models_dir.mkdir(exist_ok=True)
                
                for file_info in backup_zip.filelist:
                    if file_info.filename.startswith('models/'):
                        extract_path = models_dir / file_info.filename[7:]  # Remove 'models/' prefix
                        extract_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        with backup_zip.open(file_info) as source:
                            with open(extract_path, 'wb') as target:
                                shutil.copyfileobj(source, target)
            
            # Restore configuration
            if restore_config:
                config_dir = Path('/data/config')
                config_dir.mkdir(exist_ok=True)
                
                for file_info in backup_zip.filelist:
                    if file_info.filename.startswith('config/'):
                        extract_path = config_dir / file_info.filename[7:]  # Remove 'config/' prefix
                        extract_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        with backup_zip.open(file_info) as source:
                            with open(extract_path, 'wb') as target:
                                shutil.copyfileobj(source, target)
                
                # Restore add-on configuration
                try:
                    addon_config_data = backup_zip.read('addon_config.json')
                    with open('/data/config/restored_addon_config.json', 'wb') as f:
                        f.write(addon_config_data)
                except KeyError:
                    pass  # No add-on config in backup
            
            # Restore logs if requested
            if restore_logs:
                logs_dir = Path('/data/logs')
                logs_dir.mkdir(exist_ok=True)
                
                for file_info in backup_zip.filelist:
                    if file_info.filename.startswith('logs/'):
                        extract_path = logs_dir / f"restored_{file_info.filename[5:]}"
                        
                        with backup_zip.open(file_info) as source:
                            with open(extract_path, 'wb') as target:
                                shutil.copyfileobj(source, target)
        
        return True, f"Restoration completed. Current state backed up as {current_backup_name}"
        
    except Exception as e:
        return False, f"Restoration failed: {str(e)}"

def export_model_data():
    """Export model data for external use"""
    try:
        export_dir = Path('/data/exports')
        export_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_path = export_dir / f'ml_export_{timestamp}.json'
        
        export_data = {
            'export_info': {
                'created': datetime.now().isoformat(),
                'addon_version': '1.0',
                'export_type': 'model_data'
            },
            'model_state': {},
            'learning_history': {},
            'configuration': {}
        }
        
        # Export model state if available
        model_state_file = Path('/data/models/ml_state.pkl')
        if model_state_file.exists():
            try:
                with open(model_state_file, 'rb') as f:
                    state = pickle.load(f)
                # Convert to JSON-serializable format
                export_data['model_state'] = {
                    'confidence': float(state.get('confidence', 0)),
                    'mae': float(state.get('mae', 0)),
                    'rmse': float(state.get('rmse', 0)),
                    'cycle_count': int(state.get('cycle_count', 0)),
                    'last_prediction': float(state.get('last_prediction', 0))
                }
            except Exception:
                export_data['model_state'] = {'error': 'Failed to load model state'}
        
        # Export configuration
        config_file = Path('/data/options.json')
        if config_file.exists():
            try:
                with open(config_file, 'r') as f:
                    config = json.load(f)
                export_data['configuration'] = config
            except Exception:
                export_data['configuration'] = {'error': 'Failed to load configuration'}
        
        # Write export file
        with open(export_path, 'w') as f:
            json.dump(export_data, f, indent=2)
        
        return True, export_path
        
    except Exception as e:
        return False, str(e)

def import_model_data(import_file_path):
    """Import model data from external source"""
    try:
        import_file = Path(import_file_path)
        if not import_file.exists():
            return False, "Import file not found"
        
        with open(import_file, 'r') as f:
            import_data = json.load(f)
        
        # Validate import data structure
        required_sections = ['export_info', 'model_state', 'configuration']
        for section in required_sections:
            if section not in import_data:
                return False, f"Invalid import file: missing {section} section"
        
        # Import configuration
        if 'configuration' in import_data and import_data['configuration']:
            config_backup_path = Path('/data/config/imported_config.json')
            with open(config_backup_path, 'w') as f:
                json.dump(import_data['configuration'], f, indent=2)
        
        # Import model state
        if 'model_state' in import_data and import_data['model_state']:
            # Convert back to internal format and save
            models_dir = Path('/data/models')
            models_dir.mkdir(exist_ok=True)
            
            imported_state_path = models_dir / 'imported_ml_state.pkl'
            with open(imported_state_path, 'wb') as f:
                pickle.dump(import_data['model_state'], f)
        
        return True, "Import completed successfully"
        
    except Exception as e:
        return False, f"Import failed: {str(e)}"

def render_backup_overview():
    """Render backup system overview"""
    st.subheader("üíæ Backup System Overview")
    
    # System status
    col1, col2, col3, col4 = st.columns(4)
    
    backups = get_existing_backups()
    model_files = get_model_files()
    
    total_model_size = sum(f['size'] for f in model_files['models']) / 1024 / 1024  # MB
    total_backup_size = sum(b['size'] for b in backups) / 1024 / 1024  # MB
    
    with col1:
        st.metric("Available Backups", len(backups))
    with col2:
        st.metric("Model Data Size", f"{total_model_size:.1f} MB")
    with col3:
        st.metric("Total Backup Size", f"{total_backup_size:.1f} MB")
    with col4:
        if backups:
            days_since_backup = (datetime.now() - backups[0]['created']).days
            st.metric("Last Backup", f"{days_since_backup} days ago")
        else:
            st.metric("Last Backup", "Never")

def render_create_backup():
    """Render backup creation interface"""
    st.subheader("üîÑ Create New Backup")
    
    col1, col2 = st.columns(2)
    
    with col1:
        backup_name = st.text_input(
            "Backup Name (optional)", 
            placeholder="Leave empty for auto-generated name"
        )
        
        include_logs = st.checkbox("Include Log Files", value=True)
        include_analytics = st.checkbox("Include Analytics Data", value=True)
        
        if st.button("üîÑ Create Backup", type="primary"):
            with st.spinner("Creating backup..."):
                success, backup_path, manifest = create_backup(
                    backup_name if backup_name else None,
                    include_logs,
                    include_analytics
                )
                
                if success:
                    st.success(f"‚úÖ Backup created successfully!")
                    st.info(f"üìÅ Backup saved: {backup_path.name}")
                    
                    # Show backup details
                    if manifest:
                        st.json({
                            'backup_name': manifest['backup_name'],
                            'created': manifest['created'],
                            'files_count': len(manifest['files_backed_up']),
                            'include_logs': manifest['include_logs']
                        })
                else:
                    st.error(f"‚ùå Backup failed: {manifest}")
    
    with col2:
        st.info("**What gets backed up:**")
        st.write("‚úÖ ML model files (.pkl)")
        st.write("‚úÖ Learning state and progress")
        st.write("‚úÖ Configuration files")
        st.write("‚úÖ Add-on settings")
        
        if include_logs:
            st.write("‚úÖ System logs")
        else:
            st.write("‚è≠Ô∏è System logs (excluded)")
        
        if include_analytics:
            st.write("‚úÖ Analytics data")
        else:
            st.write("‚è≠Ô∏è Analytics data (excluded)")


def render_backup_list():
    """Render list of existing backups"""
    st.subheader("üìÅ Existing Backups")
    
    backups = get_existing_backups()
    
    if not backups:
        st.info("No backups found. Create your first backup above.")
        return
    
    # Backup list table
    backup_data = []
    for backup in backups:
        backup_data.append({
            'Name': backup['name'],
            'Created': backup['created'].strftime('%Y-%m-%d %H:%M'),
            'Size': f"{backup['size'] / 1024 / 1024:.1f} MB",
            'MD5': backup['md5'][:8] + '...',
            'Path': backup['path']
        })
    
    df = pd.DataFrame(backup_data)
    
    # Display table
    st.dataframe(
        df[['Name', 'Created', 'Size', 'MD5']],
        use_container_width=True,
        hide_index=True
    )
    
    # Backup actions
    st.subheader("üîß Backup Actions")
    
    selected_backup = st.selectbox(
        "Select backup for actions:",
        options=[b['name'] for b in backups],
        format_func=lambda x: f"{x} ({next(b['created'].strftime('%Y-%m-%d %H:%M') for b in backups if b['name'] == x)})"
    )
    
    if selected_backup:
        backup_info = next(b for b in backups if b['name'] == selected_backup)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("üîÑ Restore Backup", type="primary"):
                st.session_state['restore_backup'] = backup_info
        
        with col2:
            if st.button("üìã View Details"):
                st.session_state['view_backup'] = backup_info
        
        with col3:
            if st.button("üì§ Download"):
                st.info("Download functionality would be implemented here")
        
        with col4:
            if st.button("üóëÔ∏è Delete", type="secondary"):
                st.session_state['delete_backup'] = backup_info


def render_restore_interface():
    """Render backup restoration interface"""
    if 'restore_backup' not in st.session_state:
        return
    
    backup_info = st.session_state['restore_backup']
    
    st.subheader(f"üîÑ Restore: {backup_info['name']}")
    st.warning("‚ö†Ô∏è Restoring will replace current ML system state!")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Restore Options:**")
        restore_models = st.checkbox("Restore ML Models", value=True)
        restore_config = st.checkbox("Restore Configuration", value=True)
        restore_logs = st.checkbox("Restore Logs", value=False)
        
        st.info("Current state will be automatically backed up before restoration.")
    
    with col2:
        st.write("**Backup Information:**")
        st.write(f"Created: {backup_info['created'].strftime('%Y-%m-%d %H:%M:%S')}")
        st.write(f"Size: {backup_info['size'] / 1024 / 1024:.1f} MB")
        st.write(f"MD5: {backup_info['md5']}")
    
    col3, col4, col5 = st.columns(3)
    
    with col3:
        if st.button("‚úÖ Confirm Restore", type="primary"):
            with st.spinner("Restoring backup..."):
                success, message = restore_backup(
                    backup_info['path'],
                    restore_models,
                    restore_config, 
                    restore_logs
                )
                
                if success:
                    st.success(f"‚úÖ {message}")
                    st.info("üîÑ Restart add-on to apply restored configuration.")
                else:
                    st.error(f"‚ùå {message}")
            
            del st.session_state['restore_backup']
    
    with col4:
        if st.button("‚ùå Cancel"):
            del st.session_state['restore_backup']
            st.experimental_rerun()


def render_import_export():
    """Render import/export interface"""
    st.subheader("üì¶ Import / Export")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**üì§ Export Model Data**")
        st.caption("Export ML state and configuration as JSON")
        
        if st.button("üì§ Export Data", type="primary"):
            with st.spinner("Exporting model data..."):
                success, export_path = export_model_data()
                
                if success:
                    st.success(f"‚úÖ Export successful!")
                    st.info(f"üìÅ File: {export_path.name}")
                    st.caption(f"Location: {export_path}")
                else:
                    st.error(f"‚ùå Export failed: {export_path}")
    
    with col2:
        st.write("**üì• Import Model Data**")
        st.caption("Import ML state from JSON file")
        
        import_file = st.text_input(
            "Import file path:",
            placeholder="/data/exports/ml_export_20231126_120000.json"
        )
        
        if st.button("üì• Import Data") and import_file:
            with st.spinner("Importing model data..."):
                success, message = import_model_data(import_file)
                
                if success:
                    st.success(f"‚úÖ {message}")
                else:
                    st.error(f"‚ùå {message}")


def render_automatic_backup():
    """Render automatic backup configuration"""
    st.subheader("‚è∞ Automatic Backup Configuration")
    
    st.info("Automatic backup scheduling will be implemented in a future update.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Planned Features:**")
        st.write("‚Ä¢ Daily automatic backups")
        st.write("‚Ä¢ Weekly archive backups")
        st.write("‚Ä¢ Configurable retention policy")
        st.write("‚Ä¢ Email notifications")
        st.write("‚Ä¢ Cloud storage integration")
    
    with col2:
        st.write("**Current Recommendations:**")
        st.write("‚Ä¢ Create manual backups before major changes")
        st.write("‚Ä¢ Backup weekly during learning phase")
        st.write("‚Ä¢ Keep 3-5 recent backups")
        st.write("‚Ä¢ Test restore process periodically")
        st.write("‚Ä¢ Export critical configurations")


def render_backup_analytics():
    """Render backup analytics and insights"""
    st.subheader("üìä Backup Analytics")
    
    backups = get_existing_backups()
    
    if len(backups) < 2:
        st.info("Create more backups to see analytics and trends.")
        return
    
    # Create backup timeline chart
    backup_df = pd.DataFrame(backups)
    backup_df['size_mb'] = backup_df['size'] / 1024 / 1024
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=backup_df['created'],
        y=backup_df['size_mb'],
        mode='lines+markers',
        name='Backup Size',
        line=dict(color='blue'),
        marker=dict(size=8)
    ))
    
    fig.update_layout(
        title="Backup Size Trend",
        xaxis_title="Backup Date",
        yaxis_title="Size (MB)",
        height=300
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Backup statistics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        avg_size = backup_df['size_mb'].mean()
        st.metric("Average Size", f"{avg_size:.1f} MB")
    
    with col2:
        growth_rate = (backup_df['size_mb'].iloc[0] - backup_df['size_mb'].iloc[-1]) / len(backups)
        st.metric("Size Growth", f"{growth_rate:+.1f} MB/backup")
    
    with col3:
        backup_frequency = len(backups) / max(1, (datetime.now() - backup_df['created'].min()).days)
        st.metric("Backup Frequency", f"{backup_frequency:.1f}/day")


def render_backup():
    """Main backup page"""
    st.header("üíæ Model Backup & Restore")
    st.caption("Complete data preservation and model management system")
    
    # Auto-refresh option
    if st.button("üîÑ Refresh"):
        st.experimental_rerun()
    
    # Render main sections
    render_backup_overview()
    
    st.divider()
    
    render_create_backup()
    
    st.divider()
    
    render_backup_list()
    
    # Handle restore interface
    render_restore_interface()
    
    st.divider()
    
    render_import_export()
    
    st.divider()
    
    render_automatic_backup()
    
    st.divider()
    
    render_backup_analytics()
